{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tensor(tensor, filename):\n",
    "    \"\"\"Save tensor values to a text file\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        # If tensor is 1D\n",
    "        if len(tensor.shape) == 1:\n",
    "            for value in tensor:\n",
    "                f.write(f\"{value.item()}\\n\")\n",
    "        # If tensor is 2D\n",
    "        elif len(tensor.shape) == 2:\n",
    "            for row in tensor:\n",
    "                f.write(' '.join([f\"{x.item()}\" for x in row]) + '\\n')\n",
    "        # If tensor is 3D\n",
    "        elif len(tensor.shape) == 3:\n",
    "            for i, matrix in enumerate(tensor):\n",
    "                f.write(f\"Matrix {i}:\\n\")\n",
    "                for row in matrix:\n",
    "                    f.write(' '.join([f\"{x.item()}\" for x in row]) + '\\n')\n",
    "                f.write('\\n')\n",
    "        # If tensor is 4D\n",
    "        elif len(tensor.shape) == 4:\n",
    "            for b, batch in enumerate(tensor):\n",
    "                f.write(f\"Batch {b}:\\n\")\n",
    "                for h, head in enumerate(batch):\n",
    "                    f.write(f\"Head {h}:\\n\")\n",
    "                    for row in head:\n",
    "                        f.write(' '.join([f\"{x.item()}\" for x in row]) + '\\n')\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: Hello from the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from safetensors import safe_open\n",
    "\n",
    "# setup model and tokenizer links\n",
    "model_name = \"arnir0/Tiny-LLM\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# setup input string\n",
    "INPUT_STRING = \"Hello from the\"\n",
    "print(f\"Input string: {INPUT_STRING}\")\n",
    "\n",
    "# setup weights\n",
    "tensors_path = \"C:/Users/cfk30/.cache/huggingface/hub/models--arnir0--Tiny-LLM/snapshots/b784a70a5e6908c9148820a245d60a3347279868/model.safetensors\"\n",
    "tensors = safe_open(tensors_path, framework=\"pt\")\n",
    "\n",
    "# Embedding weights\n",
    "W_embed = tensors.get_tensor(\"model.embed_tokens.weight\")\n",
    "\n",
    "# Attention weights\n",
    "W_q = tensors.get_tensor(\"model.layers.0.self_attn.q_proj.weight\")\n",
    "W_k = tensors.get_tensor(\"model.layers.0.self_attn.k_proj.weight\")\n",
    "W_v = tensors.get_tensor(\"model.layers.0.self_attn.v_proj.weight\")\n",
    "W_o = tensors.get_tensor(\"model.layers.0.self_attn.o_proj.weight\")\n",
    "\n",
    "# Layer Norm weights\n",
    "W_ln_in = tensors.get_tensor(\"model.layers.0.input_layernorm.weight\")\n",
    "W_ln_post = tensors.get_tensor(\"model.layers.0.post_attention_layernorm.weight\")\n",
    "W_ln_final = tensors.get_tensor(\"model.norm.weight\")\n",
    "\n",
    "# MLP weights\n",
    "W_mlp_up = tensors.get_tensor(\"model.layers.0.mlp.up_proj.weight\")\n",
    "W_mlp_gate = tensors.get_tensor(\"model.layers.0.mlp.gate_proj.weight\")\n",
    "W_mlp_down = tensors.get_tensor(\"model.layers.0.mlp.down_proj.weight\")\n",
    "\n",
    "# Output head\n",
    "W_lm_head = tensors.get_tensor(\"lm_head.weight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 4])\n",
      "Embeddings shape: torch.Size([1, 4, 192])\n",
      "Model's embedding size: 192\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input string \n",
    "inputs = tokenizer(INPUT_STRING, return_tensors=\"pt\")\n",
    "batch_size = inputs.input_ids.shape[0]\n",
    "seq_len = inputs.input_ids.shape[1]\n",
    "\n",
    "# Create embeddings tensor\n",
    "embeddings = torch.zeros((batch_size, seq_len, model.config.hidden_size))\n",
    "for i in range(seq_len):\n",
    "    embeddings[:, i, :] = W_embed[inputs.input_ids[:, i]]\n",
    "# Convert embeddings to float16 to match model weights\n",
    "embeddings = embeddings.to(torch.float16)\n",
    "\n",
    "\n",
    "print(f\"Input IDs shape: {inputs.input_ids.shape}\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Model's embedding size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input embeddings layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post layer norm embeddings shape: torch.Size([1, 4, 192])\n",
      "tensor([[[-1.8030e-01, -2.7783e-01, -1.2781e-01,  1.1401e-01, -1.0205e-01,\n",
      "          -2.7441e-01,  3.4106e-01, -9.2896e-02,  3.6060e-01,  2.7417e-01,\n",
      "           1.0803e-02,  1.7957e-01,  8.5205e-02,  2.7710e-01, -2.1936e-01,\n",
      "          -2.3108e-01,  2.3132e-01, -7.1106e-02,  9.6802e-02, -2.9150e-01,\n",
      "          -3.5913e-01,  7.3193e-01, -1.6406e-01, -1.1505e-01, -7.8430e-02,\n",
      "           2.2791e-01, -4.5996e-01,  1.1304e-01,  7.9773e-02,  9.4421e-02,\n",
      "           5.2368e-02, -4.6484e-01,  1.9928e-02, -2.2327e-01,  3.3765e-01,\n",
      "          -3.1543e-01, -3.6841e-01,  5.4004e-01, -8.9783e-02,  5.6543e-01,\n",
      "          -6.7993e-02,  2.2278e-01,  6.0455e-02,  2.1533e-01, -9.0088e-02,\n",
      "          -1.9638e-02,  8.8440e-02, -5.8740e-01,  3.6035e-01, -2.0593e-01,\n",
      "          -4.3604e-01, -2.2327e-01, -1.6321e-01, -1.3831e-01,  4.8126e-02,\n",
      "          -1.4319e-01,  2.8296e-01,  6.5088e-01, -2.1399e-01, -4.3396e-02,\n",
      "           1.6785e-01, -3.0347e-01,  4.2432e-01,  2.4719e-01,  2.7197e-01,\n",
      "          -4.4727e-01,  2.4255e-01,  1.2054e-01,  6.0364e-02,  5.2100e-01,\n",
      "          -2.2131e-01, -6.9971e-01,  5.4248e-01,  6.5186e-02,  7.5989e-02,\n",
      "           3.4393e-02, -2.7246e-01, -5.8154e-01, -1.4795e-01,  4.6143e-02,\n",
      "           2.6807e-01, -2.1057e-01, -9.7900e-02,  1.9275e-01,  7.4768e-02,\n",
      "          -1.3049e-01, -3.6108e-01,  7.6843e-02,  4.8193e-01,  1.6748e-01,\n",
      "           2.6514e-01, -2.4597e-01,  6.7285e-01,  8.2275e-02,  1.3257e-01,\n",
      "          -2.6855e-02,  7.1094e-01, -2.0496e-01, -3.3447e-01, -1.2830e-01,\n",
      "           4.0454e-01, -1.0382e-01, -1.7798e-01, -1.6602e-01,  3.1592e-01,\n",
      "          -2.6147e-01, -4.0503e-01,  4.3506e-01,  3.7500e-01,  4.7583e-01,\n",
      "          -3.9844e-01,  3.6377e-01, -1.0345e-01,  2.2498e-01,  7.6904e-02,\n",
      "          -6.1707e-02,  4.9902e-01,  1.9189e-01, -1.0498e-01,  1.7419e-01,\n",
      "          -7.5951e-03,  3.6304e-01, -1.0760e-01,  6.1981e-02,  1.3110e-01,\n",
      "           4.7974e-01, -4.0308e-01,  2.0032e-01, -3.0859e-01, -1.5173e-01,\n",
      "           1.3008e-02,  1.0443e-01, -2.0166e-01,  1.0516e-01, -7.1582e-01,\n",
      "          -4.8187e-02, -2.8168e-02,  2.5244e-01,  2.0279e-02,  4.8999e-01,\n",
      "          -3.0249e-01,  4.9780e-01,  2.3999e-01, -2.3401e-01, -1.2927e-01,\n",
      "           6.3232e-02,  1.3916e-01,  1.3684e-01,  8.4473e-02,  7.4219e-01,\n",
      "          -4.4873e-01, -2.1216e-01, -1.8286e-01, -1.1035e-01, -4.2572e-02,\n",
      "          -5.5267e-02, -3.8843e-01, -1.6040e-01,  1.4624e-01, -3.4033e-01,\n",
      "          -1.0437e-01, -8.3466e-03,  3.0713e-01,  1.3477e-01, -5.9265e-02,\n",
      "           2.4402e-01,  1.9287e-01, -4.1187e-01,  2.9221e-02, -1.4087e-01,\n",
      "           4.3579e-01,  3.8232e-01, -3.3997e-02, -2.6367e-01,  2.0325e-02,\n",
      "          -1.1401e-01,  1.0437e-01,  1.5405e-01,  2.3999e-01, -4.6704e-01,\n",
      "           3.1555e-02,  1.3623e-01, -2.0911e-01, -8.6060e-02, -1.2122e-01,\n",
      "           1.6809e-01,  6.4600e-01,  7.7759e-02,  1.5881e-01,  4.0680e-02,\n",
      "           1.7578e-01,  1.3208e-01],\n",
      "         [-6.7627e-02, -1.5369e-01, -1.5796e-01,  1.0908e+00, -4.9744e-02,\n",
      "          -2.3669e-01,  3.3374e-01, -1.2482e-01,  3.8184e-01, -1.7786e-01,\n",
      "           3.5156e-02, -1.5576e-01,  4.1870e-01, -6.3965e-01, -3.0469e-01,\n",
      "          -7.0850e-01,  6.5613e-02, -4.7534e-01,  1.5527e-01, -2.1460e-01,\n",
      "          -1.2500e+00,  3.4595e-01,  7.9785e-01,  4.2090e-01, -1.6943e-01,\n",
      "          -9.0869e-01,  1.3037e-01,  1.1066e-01,  3.4937e-01, -9.3445e-02,\n",
      "           6.5332e-01,  9.1895e-01,  4.4946e-01,  1.1139e-01, -5.7178e-01,\n",
      "           6.8311e-01,  4.2188e-01,  3.1055e-01,  9.9468e-04, -1.0703e+00,\n",
      "           7.1973e-01, -1.6235e-01, -1.9397e-01,  1.3403e-01, -7.2314e-01,\n",
      "           5.4352e-02,  1.0321e-01,  1.1680e+00, -5.3662e-01, -2.0813e-01,\n",
      "           3.0859e-01,  4.1895e-01,  7.1533e-01,  1.9580e-01,  2.6245e-03,\n",
      "          -3.5547e-01,  3.3691e-01,  1.6589e-01, -4.8950e-01, -5.1562e-01,\n",
      "          -1.0010e-02,  1.6821e-01,  8.3008e-01,  5.3467e-01, -2.8101e-01,\n",
      "          -4.1064e-01,  7.0654e-01,  6.3281e-01, -1.0339e-01, -7.1045e-01,\n",
      "           1.0342e+00,  3.3472e-01,  6.0498e-01, -6.5625e-01,  1.2122e-01,\n",
      "          -4.2896e-01, -5.3174e-01,  2.5439e-01,  9.0210e-02, -5.6982e-01,\n",
      "          -3.3862e-01, -1.4575e-01,  1.2671e-01,  5.3320e-01, -5.2051e-01,\n",
      "          -6.6650e-01,  7.6904e-01, -1.4282e-01, -6.2646e-01, -4.6753e-02,\n",
      "          -9.5068e-01,  1.0468e-01,  8.9990e-01, -7.4023e-01, -8.1836e-01,\n",
      "          -3.3154e-01, -9.7266e-01,  3.7183e-01, -8.9453e-01,  1.1084e+00,\n",
      "           1.7773e-01,  2.6050e-01, -7.7441e-01, -7.4561e-01, -6.5576e-01,\n",
      "           9.2334e-01, -4.8291e-01,  2.3117e-02, -5.1758e-01, -9.2871e-01,\n",
      "           1.7639e-01,  5.2686e-01, -5.4834e-01,  1.5076e-01,  5.4834e-01,\n",
      "           8.2471e-01, -6.2305e-01,  6.2158e-01,  1.1201e+00,  6.1737e-02,\n",
      "           3.5431e-02,  9.5264e-01, -2.7710e-01, -1.3730e+00, -5.1660e-01,\n",
      "           4.0137e-01,  6.2451e-01, -5.2197e-01,  2.4329e-01,  6.6528e-02,\n",
      "           6.9043e-01, -1.1445e+00,  3.4937e-01,  1.9153e-01,  6.4307e-01,\n",
      "           2.5781e-01, -7.5732e-01, -3.6987e-01,  3.9453e-01,  9.3555e-01,\n",
      "           1.2451e+00,  5.5615e-01,  5.6836e-01, -1.9019e-01, -7.5830e-01,\n",
      "           4.0942e-01,  8.1299e-02, -1.1786e-01,  3.0542e-01,  1.5393e-01,\n",
      "          -4.5166e-01, -6.8994e-01, -2.8735e-01, -5.6592e-01, -3.8794e-01,\n",
      "           3.9233e-01, -1.0094e-02,  1.2500e-01, -2.4792e-01, -3.3130e-01,\n",
      "           4.7705e-01,  5.2686e-01,  4.0430e-01,  7.3145e-01,  9.1003e-02,\n",
      "           3.0127e-01,  2.8247e-01,  9.9072e-01,  3.4497e-01,  1.5576e-01,\n",
      "          -8.6517e-03, -7.3389e-01, -9.1309e-02,  2.3132e-01, -1.7493e-01,\n",
      "          -6.9189e-01,  4.7168e-01,  2.6758e-01,  2.7051e-01, -4.5386e-01,\n",
      "          -5.8740e-01,  5.1758e-01, -1.6943e-01, -2.5073e-01,  6.9824e-01,\n",
      "          -1.6541e-01, -1.8762e-01, -5.5176e-01, -6.2939e-01, -1.1982e+00,\n",
      "           8.0713e-01,  2.8271e-01],\n",
      "         [ 7.7637e-01,  1.6284e-01,  3.9453e-01,  4.6167e-01, -2.1155e-01,\n",
      "           2.0142e-01,  2.6929e-01, -1.5405e-01,  6.6846e-01, -9.4678e-01,\n",
      "           1.7957e-01, -5.9570e-01,  3.0151e-01,  5.8594e-01,  1.0358e-01,\n",
      "           6.3232e-02,  3.3594e-01, -1.1406e+00,  5.1953e-01, -4.1309e-01,\n",
      "          -7.3584e-01,  7.0953e-03,  1.1934e+00, -3.6353e-01,  3.5327e-01,\n",
      "          -1.6284e-01,  7.6050e-02,  1.9983e-01,  2.5171e-01, -3.4448e-01,\n",
      "          -4.8218e-01, -4.9829e-01, -1.8359e+00, -1.0215e+00, -6.4795e-01,\n",
      "          -1.5918e-01, -2.5488e-01, -7.1191e-01, -9.0918e-01, -2.8638e-01,\n",
      "           2.6855e-01,  2.5586e-01, -2.8076e-01, -3.5303e-01, -4.3311e-01,\n",
      "          -3.2642e-01,  4.7339e-01,  6.1188e-02, -2.3401e-01,  2.0203e-02,\n",
      "          -7.8857e-01,  6.9629e-01,  4.2676e-01,  4.5654e-01,  4.7510e-01,\n",
      "          -4.7363e-01, -2.5171e-01, -7.8918e-02, -3.1494e-01, -9.1211e-01,\n",
      "          -2.5894e-02, -1.6738e+00,  4.9316e-01, -3.0127e-01, -3.1396e-01,\n",
      "           2.5635e-01,  7.1167e-02, -3.5004e-02,  5.4053e-01,  6.5247e-02,\n",
      "           2.1802e-01,  8.6060e-02, -7.4402e-02,  6.1182e-01,  4.8975e-01,\n",
      "          -3.1689e-01,  7.3145e-01,  2.7905e-01,  4.9744e-02, -4.2749e-01,\n",
      "          -6.0547e-02,  5.2197e-01, -3.3716e-01,  1.1395e-01, -4.2953e-03,\n",
      "          -3.1299e-01, -4.9365e-01,  3.1885e-01, -8.5632e-02, -7.3340e-01,\n",
      "           2.7295e-01, -4.5410e-01,  1.5881e-01, -8.6609e-02, -2.8223e-01,\n",
      "          -1.7639e-01, -6.1084e-01,  2.8369e-01, -7.0068e-01,  6.9287e-01,\n",
      "          -1.7529e-01, -6.6406e-01,  8.5156e-01,  5.1807e-01, -2.2583e-01,\n",
      "           6.6895e-01, -2.0837e-01, -2.5024e-01, -4.1748e-01,  2.5415e-01,\n",
      "          -1.9690e-01,  4.4141e-01, -7.0801e-02, -5.5176e-01,  6.8652e-01,\n",
      "          -1.0559e-01,  9.5764e-02,  6.4795e-01, -6.0889e-01,  7.7490e-01,\n",
      "           3.2520e-01, -4.9243e-01, -7.0068e-01, -2.5195e-01,  1.5051e-01,\n",
      "          -5.1416e-01,  5.4321e-02,  2.0325e-01, -2.9541e-01,  2.6904e-01,\n",
      "           8.9050e-02, -1.3418e+00,  1.2490e+00,  1.1230e+00, -3.9038e-01,\n",
      "          -4.8462e-01, -1.3086e-01, -5.3174e-01, -2.0984e-01,  6.1182e-01,\n",
      "           1.4465e-01, -2.5684e-01,  3.2886e-01,  3.2446e-01, -9.0186e-01,\n",
      "           1.2891e+00,  2.5806e-01,  9.5557e-01,  4.0820e-01, -3.9526e-01,\n",
      "          -2.9883e-01, -4.0430e-01, -8.9160e-01, -1.2659e-01, -1.0479e+00,\n",
      "          -1.3467e+00, -8.8074e-02, -3.7451e-01,  3.2886e-01, -8.6426e-01,\n",
      "           4.1675e-01,  3.1738e-01,  2.1021e-01,  4.6484e-01, -9.8694e-02,\n",
      "           2.0471e-01,  3.1836e-01, -1.5515e-01,  6.2500e-01,  4.3701e-02,\n",
      "          -6.2549e-01,  5.0201e-02,  2.1875e-01,  1.1768e+00,  1.2695e-01,\n",
      "          -8.6670e-01,  1.6846e-02,  1.0419e-01, -3.1714e-01, -1.5588e-01,\n",
      "           6.5527e-01,  6.8164e-01, -1.2217e+00, -7.6294e-02,  1.4001e-01,\n",
      "          -1.3806e-01,  7.9248e-01, -4.2188e-01, -6.9824e-02,  2.3523e-01,\n",
      "           4.7943e-02, -7.2363e-01],\n",
      "         [-3.9697e-01,  4.7461e-01,  1.1151e-01,  3.9795e-01, -6.2927e-02,\n",
      "           1.1957e-01,  5.3101e-03,  8.1982e-01, -7.4365e-01, -8.1982e-01,\n",
      "          -3.5156e-01,  7.7393e-02,  3.1812e-01,  3.0371e-01,  2.0032e-01,\n",
      "          -2.8223e-01, -2.9126e-01, -7.0508e-01,  8.9746e-01,  3.5645e-01,\n",
      "          -7.0850e-01, -3.5645e-02,  6.9287e-01, -4.0601e-01, -3.0078e-01,\n",
      "          -2.4683e-01,  3.7158e-01,  2.5342e-01, -6.4355e-01, -2.8809e-01,\n",
      "           1.0559e-02, -4.1235e-01, -1.1055e+00,  8.1970e-02,  5.9619e-01,\n",
      "          -1.6443e-01, -3.5034e-01,  9.6130e-02, -6.0852e-02, -2.3730e-01,\n",
      "          -5.9717e-01, -3.1104e-01,  6.9873e-01,  7.5049e-01, -6.0938e-01,\n",
      "          -4.2090e-01,  1.0166e+00,  4.7266e-01, -6.9971e-01, -9.1553e-02,\n",
      "          -3.7183e-01,  1.9482e-01, -5.2246e-01,  2.6929e-01, -6.1523e-01,\n",
      "          -4.9805e-01,  2.5244e-01,  7.9590e-01,  1.6248e-01, -5.5469e-01,\n",
      "           6.6797e-01, -1.0166e+00,  1.0657e-01,  2.8122e-02,  1.9800e-01,\n",
      "           4.5068e-01, -3.3321e-03, -1.6113e+00,  2.8076e-01, -5.4590e-01,\n",
      "           7.6221e-01,  1.1314e-02, -1.1314e-02, -1.0312e+00,  4.6240e-01,\n",
      "           1.8726e-01,  2.9297e-01, -1.5942e-01, -2.1692e-01, -4.5142e-01,\n",
      "           2.6050e-01, -9.7949e-01,  1.8848e-01,  7.9163e-02,  2.9370e-01,\n",
      "          -4.0088e-01,  4.1748e-01,  2.1270e+00, -1.7549e+00,  7.1350e-02,\n",
      "           2.3877e-01,  5.4541e-01,  2.2424e-01, -1.1328e-01,  3.9368e-02,\n",
      "          -1.6968e-01, -2.1210e-02, -4.6948e-01, -3.2935e-01,  4.6191e-01,\n",
      "           1.4783e-01,  3.6987e-01,  5.5908e-01,  7.1094e-01,  1.0840e-01,\n",
      "          -4.5239e-01, -4.8291e-01,  4.5557e-01,  1.8978e-03,  2.5000e-01,\n",
      "           2.4121e-01, -5.0049e-01, -4.7510e-01,  1.8176e-01,  4.2578e-01,\n",
      "           3.5095e-02,  7.4707e-01,  5.3809e-01,  4.6509e-01, -3.5973e-03,\n",
      "           4.2310e-01, -1.9421e-01, -3.7354e-01, -3.1372e-01,  4.1235e-01,\n",
      "          -1.4636e-01, -1.0101e-01,  9.4873e-01,  3.3276e-01,  1.8967e-02,\n",
      "           9.1919e-02, -2.5562e-01, -3.2007e-01,  1.2295e+00,  4.6936e-02,\n",
      "          -3.6060e-01, -1.1945e-01, -2.3120e-01,  2.4524e-01, -2.5391e-01,\n",
      "          -6.6064e-01,  5.1270e-02,  5.4395e-01,  3.3081e-01, -1.6553e+00,\n",
      "          -1.6101e-01,  2.1167e-01,  1.1807e+00,  3.5767e-01,  3.0469e-01,\n",
      "           5.7764e-01, -1.8494e-01, -3.7891e-01, -8.8501e-02, -6.1279e-01,\n",
      "          -5.1758e-01, -8.4131e-01,  7.4365e-01,  9.8145e-02, -2.0801e-01,\n",
      "           1.3989e-01,  3.3765e-01, -3.9331e-01, -5.7617e-01,  8.6279e-01,\n",
      "           3.5327e-01,  4.6313e-01, -6.0156e-01,  1.3066e+00,  4.2285e-01,\n",
      "           1.8152e-01,  1.8201e-01, -1.9055e-01,  5.8136e-02, -2.1582e-01,\n",
      "           5.3192e-02,  8.1104e-01,  1.1934e+00,  3.7817e-01, -4.1168e-02,\n",
      "          -4.7607e-01,  8.4229e-01,  5.6915e-03, -3.7427e-01,  4.1260e-01,\n",
      "           3.1470e-01,  1.3721e+00, -3.2861e-01,  1.6431e-01,  4.8242e-01,\n",
      "           1.2754e+00, -5.6738e-01]]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Residual connection\n",
    "# RMSNorm\n",
    "# RMSNorm(x) = x/RMS(x) * γ\n",
    "# where:\n",
    "# RMS(x) = √(1/n Σx_i²)\n",
    "# γ = learned parameters (scale)\n",
    "\n",
    "rms = torch.sqrt(embeddings.pow(2).mean(dim=-1, keepdim=True) + model.config.rms_norm_eps)\n",
    "normalized = embeddings / rms\n",
    "post_ln_embeddings = W_ln_in * normalized\n",
    "print(f\"Post layer norm embeddings shape: {post_ln_embeddings.shape}\")\n",
    "\n",
    "print(post_ln_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare attention inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attention heads: 2\n",
      "Attention heads dimension: 96\n",
      "Q shape: torch.Size([1, 2, 4, 96])\n",
      "K shape: torch.Size([1, 2, 4, 96])\n",
      "V shape: torch.Size([1, 2, 4, 96])\n"
     ]
    }
   ],
   "source": [
    "num_Q_heads = model.config.num_attention_heads\n",
    "num_KV_heads = model.config.num_key_value_heads\n",
    "head_dim = model.config.hidden_size // num_Q_heads  # Size of each attention head\n",
    "\n",
    "print(f\"Number of attention heads: {num_Q_heads}\")\n",
    "print(f\"Attention heads dimension: {head_dim}\")\n",
    "\n",
    "\n",
    "# Calculate Q, K, V\n",
    "Q = post_ln_embeddings @ W_q.T\n",
    "K = post_ln_embeddings @ W_k.T\n",
    "V = post_ln_embeddings @ W_v.T\n",
    "\n",
    "\n",
    "# Split Q, K, V into heads\n",
    "Q = Q.view(batch_size, seq_len, num_Q_heads, Q.shape[-1] // num_Q_heads)\n",
    "K = K.view(batch_size, seq_len, num_KV_heads, K.shape[-1] // num_KV_heads)\n",
    "V = V.view(batch_size, seq_len, num_KV_heads, V.shape[-1] // num_KV_heads)\n",
    "\n",
    "# Permute tensors to get heads dimension in the right position\n",
    "Q = Q.transpose(1, 2)  # [1, 2, 6, 96]\n",
    "K = K.transpose(1, 2)  # [1, 1, 6, 96]\n",
    "V = V.transpose(1, 2)  # [1, 1, 6, 96]\n",
    "\n",
    "# Repeat K and V for each query/key head\n",
    "K = K.repeat(1, num_Q_heads, 1, 1)  # [1, 2, 6, 96]\n",
    "V = V.repeat(1, num_Q_heads, 1, 1)  # [1, 2, 6, 96]\n",
    "\n",
    "print(f\"Q shape: {Q.shape}\")\n",
    "print(f\"K shape: {K.shape}\") \n",
    "print(f\"V shape: {V.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Rotary Positional Embedding (RoPE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position indices shape: torch.Size([4]), values: tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "Dimension indices shape: torch.Size([48]), first few values: tensor([0., 2., 4., 6., 8.], dtype=torch.float16)\n",
      "Frequencies shape: torch.Size([48]), first few values: tensor([1.0000, 0.8252, 0.6812, 0.5625, 0.4641], dtype=torch.float16)\n",
      "Angles shape: torch.Size([4, 48]), sample values:\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [1.0000, 0.8252]], dtype=torch.float16)\n",
      "Cos/Sin shapes: torch.Size([4, 48]), sample cos values:\n",
      "tensor([[1.0000, 1.0000],\n",
      "        [0.5405, 0.6782]], dtype=torch.float16)\n",
      "Broadcast-ready cos shape: torch.Size([1, 1, 4, 48])\n",
      "Split Q shape: torch.Size([1, 2, 4, 48, 2])\n",
      "Q even/odd shapes: torch.Size([1, 2, 4, 48])\n",
      "Final Q_rope shape: torch.Size([1, 2, 4, 96])\n"
     ]
    }
   ],
   "source": [
    "# 1. Get dimensions from the Q tensor\n",
    "seq_len = Q.shape[2]      # 6 (sequence length)\n",
    "head_dim = Q.shape[-1]    # 96 (dimension per head)\n",
    "theta = 10000.0           # Base for frequency calculation from model config\n",
    "# 2. Create position indices: [0, 1, 2, 3, 4, 5]\n",
    "position = torch.arange(seq_len).to(torch.float16)\n",
    "print(f\"Position indices shape: {position.shape}, values: {position}\")\n",
    "\n",
    "# 3. Create dimension indices: [0, 2, 4, ..., 94]\n",
    "dim_indices = torch.arange(0, head_dim, 2).to(torch.float16)\n",
    "print(f\"Dimension indices shape: {dim_indices.shape}, first few values: {dim_indices[:5]}\")\n",
    "\n",
    "# 4. Calculate frequencies\n",
    "# For each dimension i: freq_i = 1 / (10000^(2i/dim))\n",
    "# This creates smaller frequencies for earlier dimensions and larger for later ones\n",
    "freqs = 1.0 / (theta ** (dim_indices.float() / head_dim)).to(torch.float16)\n",
    "print(f\"Frequencies shape: {freqs.shape}, first few values: {freqs[:5]}\")\n",
    "\n",
    "# 5. Compute angles for each position-frequency pair\n",
    "# This is an outer product: each position multiplied by each frequency\n",
    "angles = torch.outer(position, freqs)  # Shape: [seq_len, head_dim/2]\n",
    "print(f\"Angles shape: {angles.shape}, sample values:\\n{angles[:2, :2]}\")\n",
    "\n",
    "# 6. Calculate cos and sin of these angles\n",
    "cos = torch.cos(angles).to(torch.float16)\n",
    "sin = torch.sin(angles).to(torch.float16)\n",
    "print(f\"Cos/Sin shapes: {cos.shape}, sample cos values:\\n{cos[:2, :2]}\")\n",
    "\n",
    "# 7. Reshape cos/sin for broadcasting with Q/K\n",
    "# Add two dimensions for batch and heads\n",
    "cos = cos.view(1, 1, cos.shape[0], cos.shape[1])\n",
    "sin = sin.view(1, 1, sin.shape[0], sin.shape[1])\n",
    "print(f\"Broadcast-ready cos shape: {cos.shape}\")\n",
    "\n",
    "# 8. Split Q and K into even/odd dimensions\n",
    "# Reshape to separate the last dimension into pairs\n",
    "Q_split = Q.reshape(*Q.shape[:-1], -1, 2)\n",
    "K_split = K.reshape(*K.shape[:-1], -1, 2)\n",
    "print(f\"Split Q shape: {Q_split.shape}\")\n",
    "\n",
    "# Separate even and odd dimensions\n",
    "Q_even = Q_split[..., 0]  # Take first of each pair\n",
    "Q_odd = Q_split[..., 1]   # Take second of each pair\n",
    "K_even = K_split[..., 0]\n",
    "K_odd = K_split[..., 1]\n",
    "print(f\"Q even/odd shapes: {Q_even.shape}\")\n",
    "\n",
    "# 9. Apply rotation matrix multiplication\n",
    "# [cos -sin] [x_even] = [x_even*cos - x_odd*sin]\n",
    "# [sin  cos] [x_odd ] = [x_even*sin + x_odd*cos]\n",
    "Q_rotated_even = Q_even * cos - Q_odd * sin\n",
    "Q_rotated_odd = Q_even * sin + Q_odd * cos\n",
    "K_rotated_even = K_even * cos - K_odd * sin\n",
    "K_rotated_odd = K_even * sin + K_odd * cos\n",
    "\n",
    "# 10. Recombine even/odd dimensions\n",
    "Q = torch.stack([Q_rotated_even, Q_rotated_odd], dim=-1).reshape(Q.shape)\n",
    "K = torch.stack([K_rotated_even, K_rotated_odd], dim=-1).reshape(K.shape)\n",
    "print(f\"Final Q_rope shape: {Q.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate self attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([1, 2, 4, 96])\n",
      "K shape: torch.Size([1, 2, 4, 96])\n",
      "V shape: torch.Size([1, 2, 4, 96])\n",
      "Attention shape: torch.Size([1, 2, 4, 4])\n",
      "output shape: torch.Size([1, 2, 4, 96])\n",
      "output shape after transpose: torch.Size([1, 4, 2, 96])\n",
      "Final output shape: torch.Size([1, 4, 192])\n"
     ]
    }
   ],
   "source": [
    "# Self attention equation:\n",
    "# Attention(Q,K,V) = softmax(QK^T/√d_k)V\n",
    "# where:\n",
    "# Q = Query matrix\n",
    "# K = Key matrix \n",
    "# V = Value matrix\n",
    "# d_k = dimension of key vectors\n",
    "# √d_k = scaling factor to prevent softmax from having extremely small gradients\n",
    "\n",
    "print(f\"Q shape: {Q.shape}\")\n",
    "print(f\"K shape: {K.shape}\") \n",
    "print(f\"V shape: {V.shape}\")\n",
    "\n",
    "save_tensor(Q, \"q_nb.txt\")\n",
    "\n",
    "\n",
    "# Calculate scale factor using head_dim (not hidden_size)\n",
    "scale_factor = 1 / math.sqrt(head_dim)\n",
    "scale_factor = torch.tensor(scale_factor).to(torch.float16)\n",
    "\n",
    "# Calculate attention scores\n",
    "# K.transpose(-2, -1) will give [1, 1, 96, 6]\n",
    "scores = Q @ K.transpose(-2, -1)  # [1, 2, 6, 6]\n",
    "scores = scores * scale_factor\n",
    "\n",
    "# Create causal mask (optional, if you want to prevent attending to future tokens)\n",
    "causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "scores = scores.masked_fill(causal_mask, float('-inf')).to(torch.float16)\n",
    "\n",
    "# Apply softmax\n",
    "exp_scores = torch.exp(scores)\n",
    "exp_sum = exp_scores.sum(dim=-1, keepdim=True)\n",
    "Attention = exp_scores / exp_sum\n",
    "print(f\"Attention shape: {Attention.shape}\")\n",
    "\n",
    "# Multiply attention with V\n",
    "attn_output = Attention @ V\n",
    "print(f\"output shape: {attn_output.shape}\")\n",
    "\n",
    "# Reshape to get heads dimension in the right position\n",
    "attn_output = attn_output.transpose(1, 2)  # [1, 6, 2, 96]\n",
    "print(f\"output shape after transpose: {attn_output.shape}\")\n",
    "\n",
    "# Merge heads back together\n",
    "attn_output = attn_output.contiguous().view(batch_size, seq_len, model.config.hidden_size) \n",
    "attn_output = attn_output @ W_o.T\n",
    "print(f\"Final output shape: {attn_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-attention layer norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post layer norm output shape: torch.Size([1, 4, 192])\n"
     ]
    }
   ],
   "source": [
    "# Residual connection\n",
    "post_attn_residual = attn_output + embeddings\n",
    "# RMSNorm\n",
    "# RMSNorm(x) = x/RMS(x) * γ\n",
    "# where:\n",
    "# RMS(x) = √(1/n Σx_i²)\n",
    "# γ = learned parameters (scale)\n",
    "\n",
    "rms = torch.sqrt(post_attn_residual.pow(2).mean(dim=-1, keepdim=True) + model.config.rms_norm_eps)\n",
    "normalized = post_attn_residual / rms\n",
    "post_ln_attn_output = W_ln_post * normalized\n",
    "\n",
    "print(f\"Post layer norm output shape: {post_ln_attn_output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_proj shape: torch.Size([1, 4, 1024])\n",
      "up_proj shape: torch.Size([1, 4, 1024])\n",
      "silu_gated shape: torch.Size([1, 4, 1024])\n",
      "output shape: torch.Size([1, 4, 1024])\n",
      "final shape: torch.Size([1, 4, 192])\n"
     ]
    }
   ],
   "source": [
    "# Calculate gate and up projection\n",
    "gate_proj = post_ln_attn_output @ W_mlp_gate.T\n",
    "print(f\"gate_proj shape: {gate_proj.shape}\")\n",
    "up_proj = post_ln_attn_output @ W_mlp_up.T\n",
    "print(f\"up_proj shape: {up_proj.shape}\")\n",
    "\n",
    "# SwiGLU activation function\n",
    "silu_gated = gate_proj * torch.sigmoid(gate_proj)\n",
    "print(f\"silu_gated shape: {silu_gated.shape}\")\n",
    "output = silu_gated * up_proj\n",
    "print(f\"output shape: {output.shape}\")\n",
    "\n",
    "# Calculate down projection\n",
    "mlp_output = output @ W_mlp_down.T\n",
    "print(f\"final shape: {mlp_output.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-MLP layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post layer norm output shape: torch.Size([1, 4, 192])\n"
     ]
    }
   ],
   "source": [
    "# Post-MLP RMSNorm\n",
    "# RMSNorm(x) = x/RMS(x) * γ\n",
    "# where:\n",
    "# RMS(x) = √(1/n Σx_i²)\n",
    "# γ = learned parameters (scale)\n",
    "\n",
    "post_mlp_residual = mlp_output + post_attn_residual\n",
    "rms = torch.sqrt(post_mlp_residual.pow(2).mean(dim=-1, keepdim=True) + model.config.rms_norm_eps)\n",
    "normalized = post_mlp_residual / rms\n",
    "post_ln_mlp_output = W_ln_final * normalized\n",
    "\n",
    "print(f\"Post layer norm output shape: {post_ln_mlp_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve next predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Hello from the\n",
      "Next token: name\n",
      "Top 1: 'name' (prob: 0.306)\n",
      "Top 2: 'old' (prob: 0.279)\n",
      "Top 3: 'beginning' (prob: 0.148)\n",
      "Top 4: 'world' (prob: 0.135)\n",
      "Top 5: 'new' (prob: 0.132)\n"
     ]
    }
   ],
   "source": [
    "# Calculate logits\n",
    "logits = post_ln_mlp_output @ W_lm_head.T  # [1, 16, 32000]\n",
    "\n",
    "# Get logits for last position\n",
    "last_logits = logits[:, -1, :]  # [1, 32000]\n",
    "\n",
    "# Apply temperature scaling\n",
    "temperature = 1.0  # Start with 1.0 for debugging\n",
    "last_logits = last_logits / temperature\n",
    "\n",
    "# Get top k logits and their indices\n",
    "top_k = 5\n",
    "values, indices = torch.topk(last_logits, top_k)\n",
    "\n",
    "# Apply softmax only to top k\n",
    "exp_values = torch.exp(values)\n",
    "sum_exp_values = torch.sum(exp_values, dim=-1, keepdim=True)\n",
    "top_probs = exp_values / sum_exp_values\n",
    "\n",
    "# Sample from top k\n",
    "next_token_idx = indices[0, 0]  # Just take the highest probability for debugging\n",
    "next_token = next_token_idx.item()  # Convert to integer\n",
    "\n",
    "# Decode token to text\n",
    "predicted_word = tokenizer.decode([next_token])\n",
    "\n",
    "print(f\"Input text: {INPUT_STRING}\")\n",
    "print(f\"Next token: {predicted_word}\")\n",
    "\n",
    "# For debugging, show top 5 predictions\n",
    "for i in range(top_k):\n",
    "    token_id = indices[0, i].item()\n",
    "    prob = top_probs[0, i].item()\n",
    "    token_text = tokenizer.decode([token_id])\n",
    "    print(f\"Top {i+1}: '{token_text}' (prob: {prob:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
